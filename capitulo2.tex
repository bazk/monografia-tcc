\chapter{Robótica evolutiva}
\label{evolutiva}

\section{Introdução}

introdução

\section{Redes neurais artificiais}

Redes neurais artificias (RNAs) são sistemas computacionais inspirados em sistemas
nervosos animais capazes de aprendizado. Matematicamente, RNAs são aproximadores
universais \cite{hornik1989universal}. Um RNA é composto por uma rede de unidades
de processamento simples (neurônios). Cada neurônio possui um sinal de saída e
pode receber um ou mais sinais de entrada.

\subsection{Multi-Layer Perceptron}

Uma rede neural \textit{Multi-Layer Perceptron} (MLP) é composta por uma série de neurônios organizados em camadas, onde cada neurônio recebe, como entrada, a saída dos neurônios da camada anterior. Uma rede com uma camada intermediária é capaz de aproximar qualquer função contínua. Com duas camadas intermediárias, qualquer função pode ser aproximada \cite{cybenko1989mlp}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{figures/mlp}
    \caption{Multi-layer Perceptron}
    \label{fig:mlp}
\end{figure}

A saída (y) de um neurônio é determinada pela aplicação de uma função de ativação \(\sigma\) sobre a combinação linear ponderada de todas as suas \(n\) entradas \((x_1, x_2, \dots , x_n)\).

Matematicamente,

\[ y = \sigma ( \sum_{i=1}^{n} w_i x_i ) \]

onde \(w_i\) é um peso associado a entrada \(i\).

Diversas funções pode assumir o papel de função de ativação, sendo as mais comuns:
a função degrau (\ref{eq:degrau}) e a função sigmóide (\ref{eq:sigmoid}).

\begin{equation} \label{eq:degrau}
    \sigma (x) = \left\{
    \begin{array}{l l}
        0 & \quad \text{se } x < 0\\
        1 & \quad \text{caso contrário}
    \end{array} \right.
\end{equation}

\begin{equation} \label{eq:sigmoid}
    \sigma (x) = \frac{1}{1 + e^{-x}}
\end{equation}

É comum encontrar, em cada uma das camadas, um neurônio adicional cuja entrada é sempre \(1\). Este neurônio especial tem o nome de \textit{bias} e a finalidade de deslocar a função de ativação para direita ou esquerda.

O ajuste dos pesos \((w_1, w_2, \dots , w_n)\) é chamado treinamento e existe em duas formas:

\begin{description}
    \item[Supervisionado]: É fornecido ao algoritmo de treinamento um conjunto de entradas/saídas. O algoritmo iterativamente ajusta os pesos da rede a fim de que, dadas entradas do conjunto de treinamento, as saídas da rede aproximem-se das saídas.
    \item[Não supervisionado]: Não demanda conjunto de treinamento, os pesos
são ajustados considerando a aptidão da rede à solução do problema.
\end{description}

\subsection{Time-Delay Neural Network (TDNN)}

Estendendo os conceitos das redes MLP, uma \textit{Time-Delay Neural Network} (TDNN) permite à cada neurônio armazenar um histórico dos sinais de entrada. Isto permite que a rede ganhe sensibilidade à padrões temporais, ou seja, a rede pode adaptar-se não só a simples padrões como também a sequências de padrões \cite{kaiser1994tdnn}.

\section{Computação evolutiva}
\label{sec:evolutionary-computation}

\subsection{Algoritmos genéticos}

Algoritmos genéticos (\textit{Genetic Algorithms} - GAs) são algoritmos de otimização cuja heurística baseia-se no processo de evolução natural. Esses algoritmos codificam uma potencial solução para um problema específico em uma estrutura de dados semelhante a um cromossomo e aplica operadores de recombinação a essas estruturas a fim de preservar informação crítica \cite{whitley1994genetic}.

O algoritmo canônico inicia com uma população (geralmente aleatória) de indivíduos. Cada indivíduo representa uma possível solução ao problema e é composto de um ou mais cromossomos. Cada parâmetro da solução é codificado em um gene, ou seja, uma \textit{string} de bits. A união dos vários genes compõem um cromossomo.

Em seguida, os indivíduos são avaliados em relação a qualidade desses como uma solução do problema. A função que realiza essa avaliação é chamada função de aptidão ou função de \textit{fitness}. Finalmente, os operadores são aplicados a fim de gerar uma nova população.

\begin{algorithm}[h]
    \caption{Pseudocódigo de um algoritmo genético padrão}
    \begin{algorithmic}
        \State $P \gets $ população inicial aleatória
        \State $g \gets 0$
        \While {$g \le $ quantidade máxima de gerações}
            \State \Call{Avalia}{P}
            \State $S \gets$ \Call{Seleção}{$P$}
            \State $P \gets \varnothing$
            \ForEach {par de índividuos $(i_{1}, i_{2})$ em $S$}
                \State $P \gets$ \Call{Cruzamento}{$i_{1}, i_{2}$}
            \EndFor
            \State $P \gets $ \Call{Mutação}{$P$}
            \State $g \gets g + 1$
        \EndWhile
    \end{algorithmic}
\end{algorithm}

O operador \textbf{seleção} escolhe indivíduos para reprodução sexuada (cruzamento) ou assexuada (mutação) \cite{erik2012geneticos}.

O \textbf{cruzamento} gera novos indivíduos (\textit{offspring}) a partir da combinação de dois indivíduos selecionados, mantendo características de ambos. A taxa de cruzamento define a probabilidade de ocorrer o cruzamento entre dois indivíduos selecionados.

A \textbf{mutação} consiste na troca aleatória de alguns bits no cromossomo com probabilidade definida pela taxa de mutação.

\subsection{Algoritmos genéticos paralelos}

Algoritmos genéticos paralelos (\textit{Parallel GAs} -- PGAs) \cite{shonkwiler1993parallel} são variações dos GAs em alguns aspectos centrais aos quais a paralelização pode ser aplicada. Assim, é possível obter melhores resultados em relação a qualidade da solução e também a otimização do uso dos recursos computacionais \cite{erik2012geneticos}.

Os algoritmos genético paralelos podem ser classificados da seguinte forma \cite{cantupaz1998asurvey}:

\begin{enumerate}
    \item \textbf{Mestre-escravo}: paralelização da função de aptidão (única população).
    \item \textbf{\textit{Fine-grained}}: paralelização dos indivíduos de uma única população com frequente comunicação entre as partes.
    \item \textbf{\textit{Coarse-grained}}: diversas populações paralelas com pouca comunicação entre as partes.
\end{enumerate}

Nos algoritmos genéticos paralelos \textit{coarse-grained} (Coarse-Grained Parallel Genetic Algorithms - CGPGAs) um arquipélago é um conjunto de populações distintas denominadas ilhas e o processo de troca de indivíduos entre as ilhas é chamado migração. Dois parâmetros importantes são introduzidos: a quantidade de indivíduos que são trocados entre as ilhas (taxa de migração) e a frequência em que essas acontecem.

Outro fator importante a ser observado é a topologia dos arquipélagos, ou seja, as possibilidades de caminho para a migração entre as ilhas. Por exemplo, na topologia em anel (figura \ref{fig:}) cada ilha é conectada apenas com a próxima a fim de formar um ciclo. A figura \ref{fig:} mostra outro exemplo de topologia baseada no modelo Barabási-Albert \cite{albert2002statistical}.

\subsection{Particle Swarm Optimization}

O método introduzido por Kennedy e Eberhart \cite{kennedy1995pso} denominado \textit{Particle Swarm Optimization} (PSO) utiliza enxames de partículas para otimização de funções não-lineares. Nesse, para a solução de um problema com $n$ parâmetros, cada partícula $i$ possuí dois vetores $n$-dimensionais: posição $x_{i} = (x_{i1}, x_{i2}, \dots, x_{in})$ e velocidade $v_{i} = (v_{i1}, v_{i2}, \dots, v_{in})$. A cada iteração $t$ ambos os vetores são atualizados da seguinte maneira:

\begin{equation}
v_{i}^{t} = \omega v_{i}^{t-1} + \alpha \phi (p_{i}^{best} - x_{i}^{t-1}) + \beta \phi (g^{best} - x_{i}^{t-1})
\end{equation}

\begin{equation}
x_{i}^{t} = x_{i}^{t-1} + v_{i}^{t}
\end{equation}

onde $\phi$ é um número aleatório no interalo $[0,1]$ de distribuição uniforme, $p_{i}^{best}$ é o melhor vetor posição encontrado pela partícula $i$ (localmente) e $g^{best}$ é a melhor posição encontrada por todas as partículas (globalmente). $\omega$, $\alpha$ e $\beta$ são parâmetros do algoritmo.

Geralmente, o algoritmo inicia com uma população aleatória de partículas e termina após uma quantidade fixa de iterações.

\subsection{Discrete Particle Swarm Optimization}

Esta variação do PSO difere na representação das partículas. No \textit{Discrete Particle Swarm Optimization} (DPSO) a posição $x_{i} = (x_{i1}, x_{i2}, \dots, x_{in})$ de uma partícula $i$ está contida num espaço discreto e cada elemento do vetor velocidade $v_{ij}$ é um vetor $m$-dimensional contendo as probabilidades de $x_{ij}$ assumir cada um dos $m$ possíveis valores discretos.

Matematicamente,

\noindent\begin{minipage}{.5\linewidth}
$$
P(x_{i,j} = k) = \frac{\sigma (v_{i,j,k})}{S_{i,j}}
$$
\end{minipage}%
\begin{minipage}{.5\linewidth}
$$
S_{i,j} = \sum_{k}^{m} \sigma(v_{i,j,k})
$$
\end{minipage}\\

onde $\sigma$ é a função \textit{sigmoid}, $v$ é o vetor de velocidades e $x$ é o vetor posição.

Desse modo, a probabilidade de $x_{i,j}$ assumir o valor $k$ é determinada pela velocidade $v_{i,j,k}$. Note que $S_{i,j}$ é um coeficiente de normalização e tem a finalidade de permitir que $x_{i,j}$ possa assumir qualquer valor $k$.


\section{Robótica evolutiva}
\label{sec:evolutionary-robotics}

Segundo Nolfi et al. \cite{nolfi1994howtoevolve}, o projeto de um controlador para robôs autônomos apresenta duas grandes dificuldades:

\begin{enumerate}
    \item A coordenação das partes de um robô é extremamente difícil, tanto a nível do sistema de controle quanto a nível mecânico. A imprevisibilidade da interação entre esses dois níveis resulta em mais dificuldades.
    \item Robôs autônomos interagem com um ambiente externo e portanto o modo como esse se comporta determina os estímulos que receberá de entrada. Essa relação introduz um efeito de longo termo difícil de prever e modelar.
\end{enumerate}

Como uma forma de automatizar esse processo, os conceitos de computação evolutiva e seus algoritmos são utilizados para a construção gradual de tais controladores. Daí, a área denominada robótica evolutiva.

Na literatura da área, Brooks \cite{brooks1992artificiallife} utiliza de programação genética para construir um programa controlador em linguagem de alto nível. Dorigo e Schenepf \cite{dorigo1993geneticsbased} tratam o problema com uso de sistemas classificadores. Hoffmann e Pfister \cite{hoffmann1996evolutionary} utilizam um controlador de lógica difusa. Mas, a estratégia mais comum -- e adotada nesse trabalho -- é com o uso de redes neurais artificiais \cite{cliff1992evolvingvisually} \cite{miglino1994selection} \cite{nolfi1994phenotypic}.

% "Neural networks are resistant to noise that is massively present in robot/environment interactions."
% "The primitives components manipulated by the evolutionary process should be at the lowest level possible in order to avoid undesiderable choices made by the human designer. Synaptic weights and nodes are low level primitive components." Cliff, Harvey, and Husband (1993)