\chapter{Computação Bioinspirada}
\label{bioinspirada}

\section{Introdução}

introdução

\section{Redes Neurais Artificiais}

Redes Neurais Artificias (RNA) são sistemas computacionais inspirados em sistemas
nervosos animais capazes de aprendizado. Matematicamente, RNAs são aproximadores
universais \cite{hornik89universal}. Um RNA é composto por uma rede de unidades
de processamento simples (neurônios). Cada neurônio possui um sinal de saída e
pode receber um ou mais sinais de entrada.

\subsection{McCulloch-Pitts (MCP)}

No modelo proposto por McCulloch e Pitts \cite{mcculloch43mcp}, a saída (y) de
um neurônio artificial é determinada pela aplicação de uma função de ativação 0
sobre a combinação linear de todas as suas n entradas (x1, x2, ..., xn).
Matematicamente,

formula

onde wi é um peso associado a entrada i.

Diversar funções pode assumir o papel de função de ativação, sendo as mais comuns:
a função degrau [formula] e a função sigmóide [formula].

formulas

figure

\subsection{Perceptron}

O ajuste dos pesos das conexões wi é chamado treinamento e existe em duas formas:

1. Treinamento supervisionado: É fornecido ao algoritmo de treinamento um
conjunto de entradas/saídas. O algoritmo iterativamente ajusta os pesos da rede
a fim de que, dadas entradas do conjunto de treinamento, as saídas da rede
aproximem-se das saídas do conjunto de treinamento.

2. Treinamento não supervisionado: Não demanda conjunto de treinamento, os pesos
são ajustados considerando a aptidão da rede à solução do problema.

?? O primeiro modelo de RNA com aprendizado foi introduzido em
\cite{rosenblatt58perceptron}, o Perceptron. O perceptron consiste em uma RNA
baseada em MCP e um algoritmo de aprendizado supervisionado.

figure ?

\subsection{Multi-Layer Perceptron (MLP)}

O perceptron não resolve problemas não-lineramente separáveis, ou seja, ...

figure

Todavia, problemas não-linearmente separáveis são resolvidos por redes com uma
ou mais camadas intermediárias (também chamadas de camadas escodidas).

figure

Uma rede com uma camada intermediária é capaz de aproximar qualquer função
contínua. Com duas camadas intermediárias, qualquer função pode ser aproximada
\cite{cybenko89mlp}.

\subsection{Time-Delay Neural Network (TDNN)}

Extendendo os conceitos do MLP, uma TDNN permite à cada neurônio armazenar um
histórico limitado dos sinais de entrada. Isto permite que a rede ganhe
sensibilidade à padrões temporais \cite{kaiser94tdnn}.

\section{Controle de Robôs Móveis por RNA}

ann as robot controller

[zhang 2000]
Although many types of neural networks can be used
for classification purposes [105], our focus nonetheless is on
the feedforward multilayer networks or multilayer perceptrons
(MLPs) which are the most widely studied and used neural net-
work classifiers.

\section{Algoritmos de Otimização para Treinamento de RNA}

ga, pso, dpso, bpso, pga