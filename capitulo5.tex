\chapter{Experimentos}
\label{cha:experiments}

\section{Introdução}

Todos os experimentos detalhados neste capítulo foram executados em um computador com um processador ``AMD FX(tm)-8120 Eight-Core Processor'' de 3,1 GHz, 8 GiB de memória e placa gráfica ``AMD Radeon HD 7800 Series''. O simulador e os algoritmos implementados para este trabalho, escritos na linguagem de programação Python e C (OpenCL), estão disponíveis como software livre sob a licença GNU GPLv3 em \url{https://github.com/bazk/srs2d}.

A primeira seção (Seção \ref{sec:exp-fitness}) trata de definições básicas com relação as funções de \fitness. Os experimentos em si são divididos em duas partes: comparações entre funções de \fitness e comparações entre algoritmos de treinamento. Na primeira (Seção \ref{sec:exp-comp-fitness}), fazemos um estudo sobre diferentes funções de \fitness e o efeito de cada para resolução do problema de formação de caminho. Já na segunda parte (Seção \ref{sec:exp-comp-algorithms}), realizamos comparações entre quatro algoritmos de treinamento estudados (GA, CGPGA, PSO, DPSO) a fim de escolher o mais apto a produzir bons resultados.


\section{Funções de \fitness}
\label{sec:exp-fitness}

Para qualquer problema resolvido por um algoritmo evolutivo (ou iterativo), a função de \fitness ideal deve ser determinística. É fácil perceber que uma função de \fitness muito distante desse ideal pode ocasionar o descarte de boas soluções pelo algoritmo que a utiliza. Por exemplo, suponha que em um determinado momento na execução de um algoritmo genético -- cuja função de \fitness não é determinística -- dois indivíduo foram avaliados e um deles é de maior \fitness que o outro. Consequentemente, o algoritmo decide selecionar um dos indivíduos para reprodução e o outro é descartado. Devido ao não determinismo da função de \fitness, é possível que numa segunda avaliação dos mesmos indivíduos o que foi descartado tenha maior \fitness que aquele que foi selecionado. Logo, para obter bom desempenho em um algoritmo evolutivo, a função de \fitness escolhida deve ser determinística ou o mais próximo disso possível.

A função de \fitness F demonstrada na Seção \ref{sec:fitness} é capaz de avaliar o desempenho do enxame na solução do problema, no entanto não é determinística por dois grandes fatores aleatórios: posição das áreas alvo e posição inicial dos robôs.

Para resolver esse problema, derivam-se outras duas funções de \fitness: Função de \fitness Média (FFM), Função de \fitness Classificada (FFC).

\subsection{Função de \fitness Média}

Calcula-se a $k$-FFM de um indivíduo $i$ pela média de $k$ avaliações independentes da função de \fitness F, como visto na Equação \ref{eq:ffm}. Quanto maior o número de avaliações ($k$), mais próxima do ideal (função determinística) é a função. No entanto, essa metodologia é limitada já que o custo computacional é diretamente proporcional ao número de avaliações.

\begin{equation}
\label{eq:ffm}
k\text{-FFM} (i) = \frac{1}{k} \sum^{k} \text{F} (i)
\end{equation}

Lembrando que as funções $k$-FFM e F não são funções determinísticas.

\subsection{Função de \fitness Classificada}

Antes de mais nada, denota-se por F$_{a,d}^{*}$ uma função de \fitness semelhante a F, no entanto a simulação executada para seu cálculo contém as seguintes limitações:

\begin{enumerate}
    \item A posição das áreas alvo é obrigatoriamente simétrica em relação à origem. Ou seja, a origem do sistema é colinear e equidistante em relação às áreas alvo.
    \item O ângulo (em graus) formado pelo eixo das abscissas e uma das áreas alvo é $a$.
    \item A distância (em metros) entre as áreas alvo é $d$.
\end{enumerate}

Desse modo, a $k$-FFC$_{A,D}$ de um indivíduo $i$ é computada pela média de avaliação da F$_{a,d}^{*}$, $k$ vezes para cada combinação de $a \in A$ e $d \in D$ (Equação \ref{eq:ffc}). Como as posições das áreas alvo não são mais aleatórias (as posições dos robôs ainda é aleatória), essa função é ainda mais próxima do ideal.

\begin{equation}
\label{eq:ffc}
k\text{-FFC}_{A,D} (i) = \frac{1}{k |A| |D|} \sum^{k} \sum_{a \in A} \sum_{d \in D} \text{F}_{a,d}^{*} (i)
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Comparações entre funções de \fitness}
\label{sec:exp-comp-fitness}

Algumas instâncias das funções apresentadas na Seção \ref{sec:exp-fitness} são comparadas e analisadas nos experimentos. A primeira das instâncias é denotada por \textbf{f1} e consiste de uma 16-FFM. A função identificada por \textbf{f2} equivale a uma 1-FFC$_{A,D}$ onde $A = \{0; 45; 90; 135\}$ e $D = \{0,8; 1,0; 1,2; 1,4\}$. A terceira, \textbf{f3}, é a uma 4-FFC$_{A,D}$ onde $A = \{0; 45; 90; 135\}$ e $D = \{1,2\}$. E por fim, a \textbf{f4} também equivale a uma 4-FFC$_{A,D}$ onde $D = \{0,8; 1,0; 1,2; 1,4\}$ e $A = \{135\}$. Essas funções também podem ser vistas na Tabela \ref{tab:fitness-functions}.

\begin{table}[H]
    \centering
    \begin{tabular}{| c | c | c | c |}
        \hline
        Instância & Função & A & D \\ \hline
        \textbf{f1} & 16-FFM & -- & -- \\ \hline
        \textbf{f2} & 1-FFC$_{A,D}$ & $\{0; 45; 90; 135\}$ & $\{0,8; 1,0; 1,2; 1,4\}$ \\ \hline
        \textbf{f3} & 4-FFC$_{A,D}$ & $\{0; 45; 90; 135\}$ & $\{1,2\}$ \\ \hline
        \textbf{f4} & 4-FFC$_{A,D}$ & $\{135\}$ & $\{0,8; 1,0; 1,2; 1,4\}$ \\ \hline
    \end{tabular}
    \caption{Instâncias das funções de \fitness}
    \label{tab:fitness-functions}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Comparações entre algoritmos de treinamento}
\label{sec:exp-comp-algorithms}

Considerando que as funções de \fitness são bastante semelhantes, é suficiente a utilização de apenas uma delas a fim de comparar diferentes algoritmos. Os experimentos desta seção utilizam apenas a função de \fitness \textbf{f3}.

Os algoritmos de treinamento comparados são: \textit{Genetic Algorithm} (GA), \textit{Coarse-Crained Parallel Genetic Algorithm} (CGPGA), \textit{Particle Swarm Optimization} (PSO) e \textit{Discrete Particle Swarm Optimization}.

\subsection{\textit{Genetic Algorithm}}

A representação da solução no GA é através de uma string de bits. Os parâmetros da solução são discretizados uniformemente em valores no intervalo $[0, 256)$ e codificados em 8 bits. A concatenação dos parâmetros codificados representa um indivíduo.

O algoritmo inicia com uma uma população de 120 indivíduos gerados aleatoriamente e executa por 500 gerações. A cada geração 20 indivíduos são selecionados pelo método da roleta russa e aplicam os operadores de cruzamento e mutação gerando uma nova população (cada indivíduo selecionado gera 6 novos indivíduos). Os seis melhores indivíduos são mantidos na nova população (elitismo). A estrategia de cruzamento é a de ponto único e ocorre a uma taxa de 70\%. A inversão de cada um dos \textit{bits} dos cromossomos acontece com 3\% de probabilidade (mutação).

\subsection{\textit{Coarse-Grained Parallel Genetic Algorithm}}

Os experimentos com CGPGA utilizam quatro ilhas em anel, cada uma com uma população de 30 indivíduos. A representação da solução e os parâmetros são iguais aos descritos para o GA na seção anterior, com exceção do elitismo (que nesse caso é de 3 indivíduos) e da quantidade de indivíduos selecionados (5 indivíduos).

A execução é análoga a do GA porém com quatro instâncias (ilhas) acontecendo ao mesmo tempo. A cada 10 gerações, 5\% dos indivíduos de cada ilha são migrados para a ilha seguinte (topologia em anel).

\subsection{\textit{Particle Swarm Optimization}}

No PSO, uma solução é representada por um vetor de valores contínuos (vetor posição), nesse caso a representação da solução é direta e cada elemento do vetor equivale á um parâmetro da solução. A população de partículas é iniciada com 120 indivíduos e executa 500 iterações. Os parâmetros $\omega$, $\alpha$ e $\beta$ da Equação \ref{eq:pso-vel} escolhidos para os experimentos são 0.9, 2.0 e 2.0, respectivamente.

\subsection{\textit{Discrete Particle Swarm Optimization}}

O vetor posição no DPSO está contido num espaço discreto. Portanto, os parâmetros da solução são discretizados uniformemente em valores no intervalo $[0, 256)$ e cada elemento do vetor posição representa um parâmetro da solução. Igualmente ao PSO, a população de partículas é iniciada com 120 indivíduos e executa 500 iterações. Os parâmetros $\omega$, $\alpha$ e $\beta$ da Equação \ref{eq:pso-vel} escolhidos para os experimentos são 0.9, 2.0 e 2.0, respectivamente.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

